{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03ec26ee",
   "metadata": {},
   "source": [
    "# LaTeXpOsEd: Analyzation Stage\n",
    "\n",
    "This last step is where all the data that comes from the data mining is analyzed. It involves not just this script, but a manual inspection of the findings.\n",
    "\n",
    "Before running this script:\n",
    "\n",
    "- Complete: [3_mine_pattern-matching.ipynb](3_mine_pattern-matching.ipynb)\n",
    "- Complete: [3_mine_entity-extraction.ipynb](3_mine_entity-extraction.ipynb)\n",
    "- Complete: [3_mine_logical-filtering.ipynb](3_mine_logical-filtering.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4b119e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "import hashlib\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287be5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAPERS_FOLDER = 'data/final'\n",
    "CHARTS_FOLDER = 'data/charts'\n",
    "COMMENTS_JSONL = 'data/paper_comments.jsonl'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f053d7",
   "metadata": {},
   "source": [
    "## Comment statstics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d54df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most common file types\n",
    "file_types = Counter()\n",
    "for filename in tqdm(os.listdir(PAPERS_FOLDER)):\n",
    "    if filename.endswith('.json'):\n",
    "        with open(os.path.join(PAPERS_FOLDER, filename), 'r') as f:\n",
    "            paper = json.load(f)\n",
    "            if not paper:\n",
    "                continue\n",
    "            for file in paper:\n",
    "                ext = os.path.splitext(file)[0].lower()\n",
    "                file_types[ext] += 1\n",
    "                \n",
    "file_types.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7577abb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments statistics\n",
    "papers_with_source = 0\n",
    "papers_with_no_comments = 0\n",
    "papers_with_short_comments = 0\n",
    "\n",
    "with open(COMMENTS_JSONL, 'r') as f:\n",
    "    for line in f:\n",
    "        comment = json.loads(line)\n",
    "        papers_with_source += 1\n",
    "        if not comment['comments']:\n",
    "            papers_with_no_comments += 1\n",
    "        elif len(comment['comments']) < 100:\n",
    "            papers_with_short_comments += 1\n",
    "\n",
    "papers_with_source, papers_with_no_comments, papers_with_short_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e154cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [\n",
    "    100_000 - 92_303,\n",
    "    92_303 - 86164,\n",
    "    4586,\n",
    "    86164 - 4586\n",
    "]\n",
    "y = [\n",
    "    'No Archive',\n",
    "    'No LaTeX',\n",
    "    'No Comments',\n",
    "    'Remaining'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdeef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\n",
    "    plt.cm.tab20.colors[6], # red\n",
    "    plt.cm.tab20.colors[2], # orange\n",
    "    plt.cm.tab20.colors[3], # light orange\n",
    "    plt.cm.tab20.colors[4], # green\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "wedges, texts, autotexts = ax.pie(\n",
    "    x,\n",
    "    labels=None,  # moved labels to legend\n",
    "    colors=colors,\n",
    "    autopct=lambda pct: f\"{pct:.1f}%\" if pct >= 3 else \"\",\n",
    "    startangle=90,\n",
    "    counterclock=False,\n",
    "    pctdistance=0.8,\n",
    "    textprops={\"color\": \"#eee\", \"fontsize\": 10}\n",
    ")\n",
    "\n",
    "# Draw center circle to make it a ring\n",
    "centre_circle = plt.Circle((0, 0), 0.45, fc=\"white\")\n",
    "fig.gca().add_artist(centre_circle)\n",
    "\n",
    "# Legend on the right\n",
    "ax.legend(wedges, y, loc=\"center left\", bbox_to_anchor=(1.0, 0.5), frameon=False)\n",
    "\n",
    "# Equal aspect ratio ensures that pie is drawn as a circle\n",
    "ax.axis('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{CHARTS_FOLDER}/comment_cleanup.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8e61a1",
   "metadata": {},
   "source": [
    "## Top domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27cbea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "domains = [\n",
    "    \"github.com\", \"doi.org\", \"arxiv.org\", \"q.uiver.app\", \"stackexchange.com\",\n",
    "    \"fink-portal.org\", \"huggingface.co\", \"4open.science\", \"orcid.org\", \"docs.google.com\"\n",
    "]\n",
    "percentages = [12.7, 9.1, 8.7, 8.1, 4.0, 3.8, 3.1, 1.9, 1.1, 1.1]\n",
    "\n",
    "# Sort by percentage\n",
    "sorted_data = sorted(zip(percentages, domains), reverse=True)\n",
    "percentages_sorted, domains_sorted = zip(*sorted_data)\n",
    "\n",
    "# Offset for visibility\n",
    "offset = 5.0\n",
    "scaled_values = [p + offset for p in percentages_sorted]\n",
    "\n",
    "# Create figure\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Gradient colors\n",
    "colors = [plt.cm.Blues(0.95 - 0.6*(i/len(domains_sorted))) for i in range(len(domains_sorted))]\n",
    "\n",
    "# Draw bars (rounded edges)\n",
    "bars = ax.barh(domains_sorted, scaled_values, color=colors, height=0.9)\n",
    "for bar in bars:\n",
    "    bar.set_linewidth(0)\n",
    "    bar.set_edgecolor(\"none\")\n",
    "    bar.set_alpha(0.8)\n",
    "\n",
    "# Add text labels with fancy boxes\n",
    "for bar, value, label in zip(bars, percentages_sorted, domains_sorted):\n",
    "    ax.text(0.3, bar.get_y() + bar.get_height()/2,\n",
    "            f\"{label} ({value:.1f}%)\",\n",
    "            va=\"center\", ha=\"left\", fontsize=14, color=\"white\", fontweight=\"bold\",\n",
    "            bbox=dict(facecolor=\"black\", alpha=0.35, boxstyle=\"round,pad=0.3\"))\n",
    "\n",
    "# Remove y-axis ticks\n",
    "ax.set_yticks([])\n",
    "\n",
    "# X-axis: manual ticks (counts instead of percentage)\n",
    "ax.set_xlim(0, 20)\n",
    "ax.set_xticks([6.5, 13.5, 18])\n",
    "ax.set_xticklabels([\"500\", \"3000\", \"5000\"], fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "# Style grid\n",
    "ax.grid(axis=\"x\", linestyle=\"--\", alpha=0.7, linewidth=1.2)\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "ax.spines[\"left\"].set_visible(False)\n",
    "ax.spines[\"bottom\"].set_alpha(0.4)\n",
    "\n",
    "# Layout polish\n",
    "ax.invert_yaxis()\n",
    "\n",
    "#plt.title(\"Top Referenced Domains in LaTeX Comments\", fontsize=18, fontweight=\"bold\", pad=15)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.savefig(f\"{CHARTS_FOLDER}/top_domains.pdf\", format=\"pdf\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d7adf0",
   "metadata": {},
   "source": [
    "## Search affiliations of papers with cleaned comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da489d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_comment_article_ids = list()\n",
    "\n",
    "with open(COMMENTS_JSONL, 'r') as f:\n",
    "    for line in f:\n",
    "        article = json.loads(line)\n",
    "        if len(article['comments']) == 0:\n",
    "            empty_comment_article_ids.append(article['name'])\n",
    "            \n",
    "len(empty_comment_article_ids), empty_comment_article_ids[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed4172a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect a paper by ID\n",
    "\n",
    "target_file = 'EXAMPLE-ID.json'\n",
    "with open(f'{PAPERS_FOLDER}/{target_file}', 'r') as f:\n",
    "    paper = json.load(f)\n",
    "    \n",
    "for file in paper:\n",
    "    print(f'============================= {file} =============================')\n",
    "    print(paper[file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93246874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test affiliation search pattern\n",
    "\n",
    "pattern_affiliation = re.compile(r'\\\\(affiliation|affil|IEEEauthorblockA)?.*?\\{(.+?)\\}')\n",
    "\n",
    "tests = [\n",
    "    '\\\\affil[$\\\\dagger$]{Department of Computer Science, ABC University, D Country}\\n\\\\affil[$\\\\dagger$]{Department of Chocolate, Belgium}',\n",
    "    '\\\\affiliation{makako U}',\n",
    "]\n",
    "\n",
    "# All non-overlapping matches with positions\n",
    "for i, t in enumerate(tests, 1):\n",
    "    matches = [(m.group(2)) for m in pattern_affiliation.finditer(t)]\n",
    "    print(i, matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd6fb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "institutions = []\n",
    "\n",
    "for file_name in empty_comment_article_ids:\n",
    "    with open(FULL_PAPERS_FOLDER + '/' + file_name, 'r') as f:\n",
    "        files = json.load(f)\n",
    "        content = ''\n",
    "        for file in files:\n",
    "            content += files[file] + '\\n'\n",
    "        # Split into lines and collect any line containing a match\n",
    "        lines = content.splitlines()\n",
    "        matched_lines = []\n",
    "        for line in lines:\n",
    "            if '\\\\affil' in line or '\\\\IEEEauthorblockA' in line:\n",
    "                matched_lines.append(line)\n",
    "        institutions.extend(matched_lines)\n",
    "        \n",
    "institutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216b2853",
   "metadata": {},
   "source": [
    "further analysis with manual inspection and LLM prompting..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802939d3",
   "metadata": {},
   "source": [
    "## Validate bitcoin addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e99438",
   "metadata": {},
   "outputs": [],
   "source": [
    "B58_ALPHABET = '123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz'\n",
    "BECH32_CHARSET = 'qpzry9x8gf2tvdw0s3jn54khce6mua7l'\n",
    "BECH32_GEN = [0x3b6a57b2, 0x26508e6d, 0x1ea119fa, 0x3d4233dd, 0x2a1462b3]\n",
    "\n",
    "\n",
    "def sha256(b: bytes) -> bytes:\n",
    "    return hashlib.sha256(b).digest()\n",
    "\n",
    "\n",
    "def b58decode_check(addr: str) -> bool:\n",
    "    # Reject invalid characters\n",
    "    for c in addr:\n",
    "        if c not in B58_ALPHABET:\n",
    "            return False\n",
    "    # Convert base58 to integer\n",
    "    num = 0\n",
    "    for c in addr:\n",
    "        num = num * 58 + B58_ALPHABET.index(c)\n",
    "    # Count leading zeros\n",
    "    n_pad = 0\n",
    "    for c in addr:\n",
    "        if c == '1':\n",
    "            n_pad += 1\n",
    "        else:\n",
    "            break\n",
    "    full = num.to_bytes((num.bit_length() + 7) // 8, 'big') if num > 0 else b''\n",
    "    full = b'\\x00' * n_pad + full\n",
    "    if len(full) < 4:\n",
    "        return False\n",
    "    payload, checksum = full[:-4], full[-4:]\n",
    "    return checksum == sha256(sha256(payload))[:4]\n",
    "\n",
    "\n",
    "def bech32_polymod(values):\n",
    "    chk = 1\n",
    "    for v in values:\n",
    "        b = (chk >> 25) & 0xff\n",
    "        chk = ((chk & 0x1ffffff) << 5) ^ v\n",
    "        for i in range(5):\n",
    "            if (b >> i) & 1:\n",
    "                chk ^= BECH32_GEN[i]\n",
    "    return chk\n",
    "\n",
    "\n",
    "def bech32_hrp_expand(hrp):\n",
    "    return [ord(x) >> 5 for x in hrp] + [0] + [ord(x) & 31 for x in hrp]\n",
    "\n",
    "\n",
    "def bech32_verify_checksum(hrp, data, bech32m=False):\n",
    "    const = 0x2bc830a3 if bech32m else 1\n",
    "    return bech32_polymod(bech32_hrp_expand(hrp) + data) == const\n",
    "\n",
    "\n",
    "def bech32_decode(addr):\n",
    "    # per BIP-173/350\n",
    "    if any(ord(x) < 33 or ord(x) > 126 for x in addr):\n",
    "        return None\n",
    "    if addr.lower() != addr and addr.upper() != addr:\n",
    "        return None\n",
    "    addr = addr.lower()\n",
    "    pos = addr.rfind('1')\n",
    "    if pos == -1:\n",
    "        return None\n",
    "    hrp = addr[:pos]\n",
    "    data = addr[pos+1:]\n",
    "    if len(hrp) < 1 or len(data) < 6:\n",
    "        return None\n",
    "    if not all(x in BECH32_CHARSET for x in data):\n",
    "        return None\n",
    "    data_vals = [BECH32_CHARSET.find(c) for c in data]\n",
    "    return hrp, data_vals\n",
    "\n",
    "\n",
    "def convert_bits(data, from_bits, to_bits, pad=True):\n",
    "    acc = 0\n",
    "    bits = 0\n",
    "    ret = []\n",
    "    maxv = (1 << to_bits) - 1\n",
    "    for value in data:\n",
    "        if value < 0 or (value >> from_bits):\n",
    "            return None\n",
    "        acc = (acc << from_bits) | value\n",
    "        bits += from_bits\n",
    "        while bits >= to_bits:\n",
    "            bits -= to_bits\n",
    "            ret.append((acc >> bits) & maxv)\n",
    "    if pad:\n",
    "        if bits:\n",
    "            ret.append((acc << (to_bits - bits)) & maxv)\n",
    "    elif bits >= from_bits or ((acc << (to_bits - bits)) & maxv):\n",
    "        return None\n",
    "    return ret\n",
    "\n",
    "\n",
    "def is_valid_bech32(addr: str) -> bool:\n",
    "    dec = bech32_decode(addr)\n",
    "    if not dec:\n",
    "        return False\n",
    "    hrp, data = dec\n",
    "    if hrp not in ('bc', 'tb', 'bcrt'):\n",
    "        return False\n",
    "    # Minimum witness program structure\n",
    "    if len(data) < 7:\n",
    "        return False\n",
    "    witver = data[0]\n",
    "    prog = data[1:-6]\n",
    "    # Verify checksum for both encodings depending on version per BIP-350\n",
    "    if witver == 0:\n",
    "        if not bech32_verify_checksum(hrp, data, bech32m=False):\n",
    "            return False\n",
    "    else:\n",
    "        if not bech32_verify_checksum(hrp, data, bech32m=True):\n",
    "            return False\n",
    "    # Convert 5-bit groups to bytes and check length constraints\n",
    "    prog_bytes = convert_bits(prog, 5, 8, pad=False)\n",
    "    if prog_bytes is None:\n",
    "        return False\n",
    "    if len(prog_bytes) < 2 or len(prog_bytes) > 40:\n",
    "        return False\n",
    "    if witver == 0 and len(prog_bytes) not in (20, 32):\n",
    "        return False\n",
    "    if witver > 16:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def detect_network(addr: str) -> str:\n",
    "    # Simple heuristic: mainnet/testnet/regtest by HRP or leading version byte\n",
    "    if addr.lower().startswith('bc1'):\n",
    "        return 'mainnet'\n",
    "    if addr.lower().startswith(('tb1', 'bcrt1')):\n",
    "        return 'test/reg'\n",
    "    if addr and addr[0] in '13':\n",
    "        return 'mainnet'\n",
    "    if addr and addr[0] in 'mn2':\n",
    "        return 'test/reg'\n",
    "    return 'unknown'\n",
    "\n",
    "\n",
    "def validate_address(addr: str) -> dict:\n",
    "    kind = 'unknown'\n",
    "    valid = False\n",
    "    if addr and addr[0] in '123mn':\n",
    "        valid = b58decode_check(addr)\n",
    "        kind = 'base58'\n",
    "    elif addr.lower().startswith(('bc1', 'tb1', 'bcrt1')):\n",
    "        valid = is_valid_bech32(addr)\n",
    "        kind = 'bech32'\n",
    "    else:\n",
    "        valid = False\n",
    "    return {\n",
    "        'address': addr,\n",
    "        'valid': valid,\n",
    "        'type': kind,\n",
    "        'network': detect_network(addr)\n",
    "    }\n",
    "\n",
    "\n",
    "def validate_file(btc_file: str) -> list:\n",
    "    with open(btc_file, 'r', encoding='utf-8') as f:\n",
    "        addrs = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "    results = [validate_address(a) for a in addrs]\n",
    "    valid_count = sum(1 for r in results if r['valid'])\n",
    "    print(f'Validated {len(results)} addresses. Valid: {valid_count}.')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248104a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_address('1AGNa15ZQXAZUgFiqJ2i7Z2DPU2J6hW62i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6a3804",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_file('data/btc_addresses.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ab6964",
   "metadata": {},
   "source": [
    "## IBAN Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ed51d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-exhaustive list of country codes and their IBAN lengths\n",
    "# Source: https://www.iban.com/structure\n",
    "IBAN_LENGTHS = {\n",
    "    \"AL\": 28, \"AD\": 24, \"AT\": 20, \"AZ\": 28, \"BH\": 22, \"BE\": 16, \"BA\": 20, \"BR\": 29,\n",
    "    \"BG\": 22, \"CR\": 22, \"HR\": 21, \"CY\": 28, \"CZ\": 24, \"DK\": 18, \"DO\": 28, \"EE\": 20,\n",
    "    \"FO\": 18, \"FI\": 18, \"FR\": 27, \"GE\": 22, \"DE\": 22, \"GI\": 23, \"GR\": 27, \"GL\": 18,\n",
    "    \"GT\": 28, \"HU\": 28, \"IS\": 26, \"IE\": 22, \"IL\": 23, \"IT\": 27, \"JO\": 30, \"KZ\": 20,\n",
    "    \"XK\": 20, \"KW\": 30, \"LV\": 21, \"LB\": 28, \"LI\": 21, \"LT\": 20, \"LU\": 20, \"MK\": 19,\n",
    "    \"MT\": 31, \"MR\": 27, \"MU\": 30, \"MD\": 24, \"MC\": 27, \"ME\": 22, \"NL\": 18, \"NO\": 15,\n",
    "    \"PK\": 24, \"PS\": 29, \"PL\": 28, \"PT\": 25, \"QA\": 29, \"RO\": 24, \"SM\": 27, \"SA\": 24,\n",
    "    \"RS\": 22, \"SK\": 24, \"SI\": 19, \"ES\": 24, \"SE\": 24, \"CH\": 21, \"TL\": 23, \"TN\": 24,\n",
    "    \"TR\": 26, \"AE\": 23, \"GB\": 22, \"VA\": 22, \"VG\": 24, \"UA\": 29, \"SC\": 31, \"IQ\": 23,\n",
    "    \"BY\": 28, \"SV\": 28, \"LY\": 25, \"SD\": 18, \"BI\": 27, \"DJ\": 27, \"RU\": 33, \"SO\": 23,\n",
    "    \"NI\": 28, \"MN\": 20, \"FK\": 18, \"OM\": 23, \"YE\": 30, \"HN\": 28\n",
    "}\n",
    "\n",
    "# Optional: relaxed structural regex (2 letters, 2 digits, then alphanumerics)\n",
    "IBAN_RE = re.compile(r'^[A-Z]{2}[0-9]{2}[A-Z0-9]+$')\n",
    "\n",
    "def _alnum_to_int_str(s: str) -> str:\n",
    "    # Map A..Z -> 10..35, digits remain\n",
    "    out = []\n",
    "    for ch in s:\n",
    "        if ch.isdigit():\n",
    "            out.append(ch)\n",
    "        else:\n",
    "            out.append(str(ord(ch) - 55))  # ord('A')=65 -> 10\n",
    "    return ''.join(out)\n",
    "\n",
    "def _mod97_large(num_str: str) -> int:\n",
    "    # Compute num_str % 97 without big ints by chunking\n",
    "    remainder = 0\n",
    "    for ch in num_str:\n",
    "        remainder = (remainder * 10 + ord(ch) - 48) % 97\n",
    "    return remainder\n",
    "\n",
    "def validate_iban(iban: str) -> bool:\n",
    "    if iban is None:\n",
    "        return False\n",
    "    # Normalize: remove spaces and make uppercase\n",
    "    iban_clean = re.sub(r'\\s+', '', iban).upper()\n",
    "    # Basic structure check\n",
    "    if len(iban_clean) < 4 or not IBAN_RE.match(iban_clean):\n",
    "        return False\n",
    "    country = iban_clean[:2]\n",
    "    if country not in IBAN_LENGTHS:\n",
    "        return False\n",
    "    if len(iban_clean) != IBAN_LENGTHS[country]:\n",
    "        return False\n",
    "    # Rearrange and convert\n",
    "    rearranged = iban_clean[4:] + iban_clean[:4]\n",
    "    numeric = _alnum_to_int_str(rearranged)\n",
    "    # MOD 97 must equal 1\n",
    "    return _mod97_large(numeric) == 1\n",
    "\n",
    "samples = [\n",
    "    \"GB33 BUKB 202015 55555555\",\n",
    "    \"DE75512108001245126199\",\n",
    "    \"FR7630006000011234567890189\",\n",
    "    \"GB00BUKB20201555555555\", # Incorrect\n",
    "]\n",
    "for s in samples:\n",
    "    print(s, \"=>\", validate_iban(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a39f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_valid = 0\n",
    "with open(\"data/IBAN.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        iban = line.strip()\n",
    "        if iban:\n",
    "            is_valid = validate_iban(iban)\n",
    "            print(iban, \"=>\", is_valid)\n",
    "            if is_valid:\n",
    "                total_valid += 1\n",
    "total_valid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
